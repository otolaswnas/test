Dzięki za liczby – to jest sedno problemu.

Co widać z Twoich danych
- lsof -p … | wc -l = 13 229 otwartych deskryptorów
- LimitNOFILE = 16 384 (soft/hard)

Jesteś bardzo blisko limitu FD (ponad 80%). Gdy liczba socketów/pliki chwilowo skoczy (np. przypływ danych, retry, okresowe wywołania management API), Logstash zabraknie deskryptorów i nowe połączenia HTTP/TLS do Elasticsearch zaczną padać na timeouty/HostUnreachable. Dodatkowo wcześniej pokazałeś tysiące ESTABLISHED – to potwierdza, że większość FD to gniazda sieciowe.

Co zrobić (kroki wprost pod RHEL 8 + Logstash 8.14.3)

1) Podnieś twardo limit otwartych plików dla usługi logstash
- systemd override (rekomendowane):
```
sudo systemctl edit logstash
```
W edytorze wklej:
```
[Service]
LimitNOFILE=262144
```
Zapisz, potem:
```
sudo systemctl daemon-reload
sudo systemctl restart logstash
```
Sprawdź:
```
cat /proc/$(pgrep -f org.logstash.Logstash)/limits | grep -i "Max open files"
```
Powinno pokazać ≥ 262144.

- (opcjonalnie) PAM/limits – przydatne, jeśli kiedyś odpalisz LS “ręcznie”:
```
echo -e "logstash soft nofile 262144\nlogstash hard nofile 262144" | sudo tee /etc/security/limits.d/99-logstash.conf
```

2) Wymuś preferencję IPv4 w JVM (eliminuje losowe próby AAAA po czasie)
- dodaj do tego samego drop‑in (albo do /etc/sysconfig/logstash):
```
[Service]
Environment=LS_JAVA_OPTS=-Djava.net.preferIPv4Stack=true -Djava.net.preferIPv6Addresses=false
```
I restart (jak wyżej).

3) Włącz TCP keepalive i ustaw porty efemeryczne/FIN timeout (na hoście)
- /etc/sysctl.d/99-logstash-keepalive.conf:
```
net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_keepalive_intvl = 15
net.ipv4.tcp_keepalive_probes = 4
```
- /etc/sysctl.d/99-logstash-net.conf:
```
net.ipv4.ip_local_port_range = 10240 60999
net.ipv4.tcp_fin_timeout = 15
```
Zastosuj:
```
sudo sysctl --system
```

4) Ogranicz i “uzdrawiaj” pulę połączeń HTTP w output Elasticsearch
W pliku pipeline (np. /etc/logstash/conf.d/50-output-elasticsearch.conf) dopisz/zmień:

```
output {
  elasticsearch {
    hosts => ["https://A.B.C.D:9200"]      # na test wpisz jeden pewny endpoint (IPv4 lub FQDN z rekordem A)
    user  => "logstash_writer"
    password => "${ES_PASSWORD}"

    ssl => true
    cacert => "/etc/logstash/certs/http_ca.crt"

    # Wyłącz ILM/setup na czas stabilizacji (często to one timeoutują)
    manage_template => false
    ilm_enabled     => false
    index           => "logstash-%{+YYYY.MM.dd}"

    # Pool/keepalive/timeouty – ogranicz liczbę socketów i wycinaj martwe idle
    pool_max => 200
    pool_max_per_route => 100
    validate_after_inactivity => 60
    resurrect_delay => 5

    connect_timeout => 30
    request_timeout => 60
    socket_timeout  => 60
  }
}
```

Wyjaśnienie:
- pool_max / pool_max_per_route: górny limit socketów w puli (globalnie i na dany host). Zbijesz liczbę ESTABLISHED do rozsądnego poziomu.
- validate_after_inactivity: każde połączenie “przetestuj” po 60 s bezczynności – martwe idle znikną, nie będą powodować SocketTimeout przy kolejnym użyciu.
- resurrect_delay: szybciej “wstaje” host oznaczony jako martwy (przy chwilowych problemach).
- timeouts: sensowne wartości, żeby nie wisieć zbyt długo.

5) Restart Logstasha i obserwacja
```
sudo systemctl restart logstash
journalctl -u logstash -f
```
Po kilkunastu minutach:
- ss -s – ESTAB powinno spaść o rząd wielkości; TIME_WAIT nie musi być duże (przy keepalive).
- lsof -p $(pgrep -f org.logstash.Logstash) | wc -l – powinno być dużo dalej od limitu (przy LimitNOFILE 262k margines jest ogromny).

6) Jeśli używasz listy wielu hostów w “hosts => […]”
- na czas stabilizacji trzymaj tylko jeden pewny endpoint. Każdy host w liście to oddzielny “route” i osobna pula socketów → mnożnik FD. Gdy ES stoi za VIP/DNSLB – preferuj jeden FQDN.

7) Gdy problem powraca (rzadko)
- sprawdź, czy CLOSE_WAIT nie rośnie:
  ```
  ss -tan state close-wait | wc -l
  ```
  Jeśli tak – to peer (ES/LB) zamyka połączenia a klient nie sprząta – validate_after_inactivity i keepalive zwykle to leczą.
- Sprawdź, czy ES nie jest przeciążony na HTTP:
  ```
  GET /_nodes/stats/thread_pool?human&filter_path=**.http.*
  ```
  Jeśli http.current_open/queue/rejected wysokie – to też będzie dawało socket timeouty: rozważ zmniejszenie pool_max w LS lub skalowanie ingest po stronie ES.

Podsumowanie
- W Twoich liczbach widać symptom “zbyt wiele FD/soketów” i zbyt niski limit – to naturalnie kończy się timeoutami po czasie.
- Podniesienie LimitNOFILE + TCP keepalive + wymuszenie IPv4 + ograniczenie puli/validação idle w output-elasticsearch praktycznie rozwiązuje “po czasie” HostUnreachable/SocketTimeout w środowiskach bez proxy/LB.
- Jeśli chcesz, podeślij po 30–60 minutach nowe:
  - ss -s
  - lsof -p $(pgrep -f org.logstash.Logstash) | wc -l
  - i fragment loga (jeśli coś jeszcze sypie),
  to potwierdzimy, że FD/ESTAB spadły i LS pracuje stabilnie.

  --------------------------------

curl -s -u USER:PASS https://ES:9200/_security/role/<role_name> | jq -r '
  to_entries[] | .key as $r |
  .value.indices[] | {role:$r, names:.names, privileges:.privileges}'

  ---------------------

Poniżej masz kompletny, “od A do Z” przepis co dodać do bieżącego Charts repo (template chart APM) i do values repo (per klaster), aby:

- cyklicznie wykonywać apm-server test output (sprawdza Kafka output),
- wystawiać własną metrykę na porcie 8888 pod /metrics (Prometheus text),
- zbierać ją przez Prometheusa w OCP (User Workload Monitoring) przez Service + ServiceMonitor,
- bez modyfikowania obrazu APM i bez zależności od Kafki/ES (metryka powstaje lokalnie).

Architektura
- initContainer (apm image): kopiuje binarkę apm-server do wspólnego wolumenu /tools,
- sidecar “apm-output-check”: uruchamia co X sek. apm-server test output z tą samą konfiguracją co APM i generuje plik /metrics/metrics, równolegle serwuje /metrics http na 8888 (busybox httpd),
- (opcjonalnie) sidecar używa tych samych env/sekretów i mountów co główny kontener (jeśli Twoje output.kafka korzysta z env i/lub plików przez VSS CSI, skrypt będzie miał tę samą konfigurację i ścieżki),
- Service + ServiceMonitor: zbiera apm_kafka_output_ok, apm_kafka_output_reachable_brokers, apm_kafka_output_last_run_ts.

Krok 1. Dodaj “włącznik” i parametry w values.yaml (w repo z values dla klastra)

W pliku values dla danego OCP klastra dopisz sekcję (przykład):

```yaml
metricsProbe:
  enabled: true
  port: 8888
  intervalSeconds: 300           # co 5 min (możesz dać 86400 = raz dziennie)
  ocpCluster: "ocp-prod-1"       # nazwa klastra (etykieta w metrykach)
  # użyj obrazu z allowliste: busybox (httpd) lub python (http.server)
  sidecarImage: "busybox:1.36"   # lub "registry.local/base/busybox:1.36"
  initImage: "registry.local/elastic/apm-server:8.14.3"  # ten sam obraz co główny APM (żeby skopiować binarkę)
  # dopnij te same env i mounty co główny kontener, jeśli APM bierze output.kafka z env/plików:
  inheritEnvFromMain: true       # jeżeli główny kontener ma envFrom (sekret z SASL/hasłami)
  inheritSecretMounts: true      # jeżeli montujesz pliki TLS/keystore (PEM/PKCS12/JKS)
```

Uwaga:
- ocpCluster pokaże się jako label w metrykach, podobnie namespace (Downward API).
- Jeśli w klastrze nie wolno pobierać z docker.io, wskaż sidecarImage/initImage z Waszego registry.

Krok 2. Dodaj ConfigMap ze skryptem (templates/configmap-metrics.yaml)

Do charts repo (templates/) dodaj plik configmap z “apm-kafka-output.sh”:

offline/apm-server/templates/configmap-metrics.yaml
```yaml
{{- if .Values.metricsProbe.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "apm-server.fullname" . }}-metrics-script
  labels:
    app.kubernetes.io/name: {{ include "apm-server.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
data:
  apm-kafka-output.sh: |
    #!/bin/sh
    set -eu
    APM_BIN="${APM_BIN:-/tools/apm-server}"              # binarka skopiowana przez initContainer
    APM_CFG="${APM_CFG:-/usr/share/apm-server/apm-server.yml}"
    METRICS_DIR="${METRICS_DIR:-/metrics}"
    PORT="${PORT:-{{ .Values.metricsProbe.port }}}"
    INTERVAL_SECONDS="${INTERVAL_SECONDS:-{{ .Values.metricsProbe.intervalSeconds }}}"
    CLUSTER="${OCP_CLUSTER:-{{ .Values.metricsProbe.ocpCluster | default "unknown" }}}"
    NAMESPACE="${POD_NAMESPACE:-unknown}"

    mkdir -p "$METRICS_DIR"
    # start httpd (busybox) i trzymaj w tle
    {{- if (hasPrefix "busybox" .Values.metricsProbe.sidecarImage) }}
    httpd -f -p "$PORT" -h "$METRICS_DIR" &
    {{- else }}
    # jeśli użyjesz pythonowego sidecara, httpd nie wystartuje tu (serwuje sidecar)
    :
    {{- end }}
    HTTPD_PID=$! 2>/dev/null || true
    trap 'kill $HTTPD_PID 2>/dev/null || true; exit 0' INT TERM

    while true; do
      OUT="$("$APM_BIN" test output -c "$APM_CFG" 2>&1 || true)"
      RC=$?
      BROKERS=$(printf '%s\n' "$OUT" | awk '/brokers/{for(i=1;i<=NF;i++) if($i ~ /^[0-9]+$/){print $i; exit}}')
      [ -z "${BROKERS:-}" ] && BROKERS=0
      OK=$([ $RC -eq 0 ] && echo 1 || echo 0)
      TS=$(date +%s)

      cat > "$METRICS_DIR/metrics" <<EOF
# HELP apm_kafka_output_ok 1 if apm-server test output succeeded (exit code 0)
# TYPE apm_kafka_output_ok gauge
apm_kafka_output_ok{cluster="{{ .Values.metricsProbe.ocpCluster | default "unknown" }}",namespace="$NAMESPACE"} $OK
# HELP apm_kafka_output_reachable_brokers Brokers reported as reachable by test output
# TYPE apm_kafka_output_reachable_brokers gauge
apm_kafka_output_reachable_brokers{cluster="{{ .Values.metricsProbe.ocpCluster | default "unknown" }}",namespace="$NAMESPACE"} $BROKERS
# HELP apm_kafka_output_last_run_ts Unix time of last test execution
# TYPE apm_kafka_output_last_run_ts gauge
apm_kafka_output_last_run_ts{cluster="{{ .Values.metricsProbe.ocpCluster | default "unknown" }}",namespace="$NAMESPACE"} $TS
EOF
      sleep "$INTERVAL_SECONDS"
    done
{{- end }}
```

Krok 3. Rozszerz Deployment (templates/deployment.yaml) – initContainer, sidecar, wolumeny

W pliku templates/deployment.yaml dodaj (we właściwych miejscach):

a) Volumes (shared):
```yaml
      volumes:
      {{- if .Values.apmConfig }}
      - name: apm-config
        configMap:
          name: {{ include "apm-server.fullname" . }}-config
      {{- end }}
      {{- range .Values.secretMounts }}
      - name: {{ .name }}
        secret:
          secretName: {{ .secretName }}
          {{- if .defaultMode }}defaultMode: {{ .defaultMode }}{{- end }}
      {{- end }}
      {{- if .Values.metricsProbe.enabled }}
      - name: tools
        emptyDir: {}
      - name: metrics-dir
        emptyDir: {}
      - name: metrics-script
        configMap:
          name: {{ include "apm-server.fullname" . }}-metrics-script
          defaultMode: 0755
      {{- end }}
      {{- if .Values.extraVolumes }}
{{ toYaml .Values.extraVolumes | indent 6 }}
      {{- end }}
```

b) initContainer (kopiuje apm-server do /tools):
```yaml
      {{- if .Values.metricsProbe.enabled }}
      initContainers:
      - name: get-apm-binary
        image: {{ .Values.metricsProbe.initImage | quote }}
        command: ["sh","-c","cp /usr/share/apm-server/apm-server /tools/apm-server && chmod +x /tools/apm-server"]
        volumeMounts:
        - name: tools
          mountPath: /tools
      {{- end }}
```

c) Sidecar “apm-output-check” i ewentualny sidecar http (jeśli nie używasz busyboxa w probe)

Wstaw w sekcji containers dodatkowo (po głównym kontenerze apm-server):

```yaml
      {{- if .Values.metricsProbe.enabled }}
      - name: apm-output-check
        image: {{ .Values.metricsProbe.sidecarImage | quote }}
        command: ["/bin/sh","-c","/scripts/apm-kafka-output.sh"]
        env:
        - name: OCP_CLUSTER
          value: {{ .Values.metricsProbe.ocpCluster | quote }}
        - name: POD_NAMESPACE
          valueFrom: { fieldRef: { fieldPath: metadata.namespace } }
        - name: PORT
          value: {{ printf "%d" .Values.metricsProbe.port | quote }}
        - name: INTERVAL_SECONDS
          value: {{ printf "%d" .Values.metricsProbe.intervalSeconds | quote }}
        volumeMounts:
        - { name: tools,         mountPath: /tools,          readOnly: true }
        - { name: metrics-dir,   mountPath: /metrics }
        - { name: metrics-script,mountPath: /scripts/apm-kafka-output.sh, subPath: apm-kafka-output.sh }
        # Zamontuj tę samą konfigurację i sekrety co główny kontener, by test miał identyczne środowisko:
        - { name: apm-config,    mountPath: /usr/share/apm-server/apm-server.yml, subPath: apm-server.yml, readOnly: true }
        {{- if .Values.metricsProbe.inheritSecretMounts }}
        {{- range .Values.secretMounts }}
        - { name: {{ .name }},  mountPath: {{ .path }}, readOnly: true }
        {{- end }}
        {{- end }}
        {{- if .Values.metricsProbe.inheritEnvFromMain }}
        envFrom:
        {{- if .Values.envFrom }}
{{ toYaml .Values.envFrom | indent 8 }}
        {{- end }}
        {{- if .Values.env }}
        # (opcjonalnie) pojedyncze env
        {{- end }}
        {{- end }}
        ports:
        - name: metrics
          containerPort: {{ .Values.metricsProbe.port }}
      {{- end }}
```

Jeśli nie chcesz, by “apm-output-check” sam wystawiał httpd, możesz rozdzielić na dwa sidecary:
- apm-output-check: generuje /metrics/metrics,
- metrics-httpd: serwuje http (użyj python:3.11-alpine → python -m http.server 8888 -d /metrics).

Krok 4. Service + ServiceMonitor (zbiórka przez Prometheusa)

Dodaj 2 pliki do templates:

templates/service-metrics.yaml
```yaml
{{- if .Values.metricsProbe.enabled }}
apiVersion: v1
kind: Service
metadata:
  name: {{ include "apm-server.fullname" . }}-metrics
  labels:
    app.kubernetes.io/name: {{ include "apm-server.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
spec:
  selector:
    app.kubernetes.io/name: {{ include "apm-server.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
  ports:
  - name: metrics
    port: {{ .Values.metricsProbe.port }}
    targetPort: metrics
    protocol: TCP
{{- end }}
```

templates/servicemonitor.yaml (jeśli UWM jest włączony; namespace ten sam co APM):
```yaml
{{- if .Values.metricsProbe.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: {{ include "apm-server.fullname" . }}-metrics
  labels:
    app.kubernetes.io/name: {{ include "apm-server.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "apm-server.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  endpoints:
  - port: metrics
    interval: 1m
    path: /metrics
{{- end }}
```

Uwaga OCP:
- Upewnij się, że User Workload Monitoring jest włączony w klastrze. ServiceMonitor w Twoim namespace powinien być zebrany przez UWM bez dodatkowych adnotacji. Jeśli macie własne selektory, dopasuj labels/selector do waszych reguł.

Krok 5. Co się pojawi w Prometheusie (metryki)
- apm_kafka_output_ok{cluster="ocp-prod-1",namespace="<ns>"} 1|0
- apm_kafka_output_reachable_brokers{…} N
- apm_kafka_output_last_run_ts{…} <epoch>

Krok 6. Alerty (przykładowe PromQL)
- Output niedostępny:
  apm_kafka_output_ok == 0
- Zero brokerów:
  apm_kafka_output_reachable_brokers == 0
- Wykonanie nie odświeża się (proces stoi):
  time() - apm_kafka_output_last_run_ts > 2*60*60

Dlaczego to działa
- test output używa tej samej konfiguracji (apm-server.yml + te same mounty/env co APM),
- metryka powstaje w Podzie i jest wystawiona lokalnie (nie wymaga Kafki/ES),
- Prometheus z OCP zbiera przez ServiceMonitor.

Najczęstsze pułapki
- initImage musi odpowiadać wersji APM (żeby ścieżka /usr/share/apm-server/apm-server była poprawna).
- jeżeli output.kafka korzysta z env (SASL), pamiętaj o inheritEnvFromMain: true i envFrom w values, by sidecar odziedziczył te same sekrety.
- VSS (Vault): jeśli APM ma pliki z Vault przez CSI, sidecar też je montuje (inheritSecretMounts: true).
- Busybox dostępność: jeśli docker.io zablokowany, użyj obrazu z allowlisty (mirror busybox/UBI+python).

Jeśli chcesz, żebym scalił powyższe fragmenty do Twojej wersji chartu (np. masz już extraVolumes w chart’cie), wklej templates/deployment.yaml (fragment spec) – zrobię diff 1:1.
